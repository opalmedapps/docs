{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Opal Documentation","text":"<p>TBD</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":"<ul> <li>Add Code Review Guidelines (!2)</li> </ul>"},{"location":"changelog/#initial-version","title":"[Initial version]","text":"<ul> <li>Add software versions in use at O-HIG</li> <li>Add Software Engineering related documentation (migrated from Google Docs)</li> <li>NEW: Initial release.</li> </ul>"},{"location":"deploy/","title":"Deploying the Opal solution","text":"<p>The Opal PIE is typically deployed in a hospital and only accessible within the hospital's network. The user applications are deployed and maintained by the Opal Health Informatics Group (O-HIG).</p>"},{"location":"deploy/#deploying-the-opal-pie","title":"Deploying the Opal PIE","text":""},{"location":"deploy/#deployment-diagram","title":"Deployment diagram","text":"<p>Relationships between components on the same host are left out for brevity (except those making use of third-party components).</p>"},{"location":"deploy/#user-applications","title":"User Applications","text":""},{"location":"deploy/#deployment-diagram_1","title":"Deployment diagram","text":""},{"location":"deploy/integration/","title":"Hospital Integration","text":"<p>An institution or hospital can integrate their data sources with the Opal solution through a series of REST API endpoints provided by the Opal Application layer. In addition, hospitals must provide some endpoints to Opal in order to facilitate patient demographic lookups, historical data fetching, etc.</p> <p>Opal source data APIs are provided by four subcomponents within the application layer. Those are:</p> <ul> <li>Backend</li> <li>OpalAdmin</li> <li>Opal-Labs</li> <li>ORMS If wait room support is enabled at hospital</li> </ul> <p>In order to successfully integrate the Opal solution with a hospital data system, the above mentioned application container images must be deployed to an application server and configured with database access, SSL certificates, and environment configuration.</p> <p>TODO: Link to external documentation on deployment/ansible scripts, Greg task.</p>"},{"location":"deploy/integration/#authentication","title":"Authentication","text":"<p>Depending on which Opal application is providing the endpoint, the authentication method will be slightly different.</p>"},{"location":"deploy/integration/#opal-backend","title":"Opal-Backend","text":"<p>The Opal-Backend is built on Django and uses the Django REST Framework which provides support for token-based authentication. During the setup of the Opal application layer, an administrator can issue the hospital data system an API token which should be appended to the headers section of all API requests to the Opal-Backend, for example:</p> <pre><code>curl --location 'https://{server-Opal}/api/' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Token 111aaa111bbb222ccc333ddd444ddde555fff6666'\n</code></pre>"},{"location":"deploy/integration/#opal-admin","title":"Opal-Admin","text":"<p>Opal-Admin refers to the legacy php system originally built to provide backend support to the Opal Administrative web applications. It exposes an authorization endpoint for system users, based on a basic username/password combination for that system user. Opal-Admin will respond to successful calls at this endpoint with an array of values corresponding to the specific system user and their preferences and permissions. Also included in the response will be a session/cookie string that should be appended to the headers of future request(s) to regular non-authentication endpoints. For example:</p> <pre><code>curl --location 'https://{server-Opal}/opalAdmin/user/system-login' \\\n--header 'Content-Type: application/x-www-form-urlencoded'\n</code></pre> <p>Handle the response and append the cookie string to the next request:</p> <pre><code>curl --location 'https://{server-Opal}/opalAdmin/patient/get/patient-exist' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--header 'Cookie: sessionId=zxcvbnm1234567890qwertyuiop' \\\n--data 'mrn=1111111&amp;site=RVH'\n</code></pre>"},{"location":"deploy/integration/#opal-labs","title":"Opal-Labs","text":"<p>Opal-labs is a small application that handles the fetching, processing, and storage of patient lab test results. This application does not contain support for authentication and is therefore protected at the reverse proxy level via Basic Authentication (see the configuration) to ensure that all requests are authenticated. During setup of the Opal application server, a new basic auth hashed username/password pair should be generated by following the steps below. The resulting pair can be Base64 encoded and appended to the request headers with the Authorization tag.</p>"},{"location":"deploy/integration/#basic-authentication-with-traefik","title":"Basic Authentication with Traefik","text":"<p>Use the <code>htpasswd</code> utility to create a bcrypt hash, pressing enter when given the opportunity to enter an additional password for the hash. For example:</p> <pre><code>echo $(htpasswd -nB hospital_integration_engine) | sed -e s/\\\\$/\\\\$\\\\$/g\n</code></pre> <p>The username and password used in the Basic Authentication header request from the hospital integration engine needs to be base64 encoded. So:</p> <pre><code>echo -n 'hospital_integration_engine:$$2y$$05$$lQUmd4J/8ygoe4d4EOm6WeisBNdYFCMvBgeCkDnc2q9loUrMeEkQ.' | base64\n</code></pre> <p>The base64 representation of the username:password can then be added as an Authorization header in the destination connector settings for our labs channel, prepended by the string 'Basic' to indicate the auth type.</p> <pre><code>--header 'Authorization Basic NldlaXNCTmRZRkNNdkJnZUNrRG5jMnE5bG9Vck1lRWtRLg=='\n</code></pre>"},{"location":"deploy/integration/#opal-rms","title":"Opal-RMS","text":"<p>Opal-RMS separates private from public APIs and thus any calls to the public API endpoints don't require authentication by default.</p>"},{"location":"deploy/integration/#data-format","title":"Data Format","text":"<p>In general the expectation for all Opal API is that payloads and responses are transmitted in JSON format, with a few exceptions.</p> <ul> <li>As an experimental feature, the pharmacy data endpoint within the Opal-backend (<code>/api/patients/${uuid}/pharmacy</code>) was created with a built-in HL7 parsing class, the accepted data format is <code>application/hl7v2+er7</code>.</li> <li>In the <code>Requirements for Hospital Endpoints</code> section (see below), the sending of patient weight measurement PDFs from the wait room management system is expected to be sent with XML data containing a base64 string encoding of the measurement PDF.</li> </ul>"},{"location":"deploy/integration/#openapi-schemas-for-opal-source-data","title":"OpenAPI Schemas for Opal Source Data","text":"<p>In each of the Opal applications there is an <code>openapi.yml</code> file providing full details of all source data endpoints that a hospital can use to send data into the Opal Application Layer. For the <code>Opal-Backend</code>, we use drf-spectacular) to dynamically generate the openapi file and render as a swagger doc. This swagger page is accessible for authenticated users via <code>/api/schema/swagger-ui</code>. For convenience, all endpoints in all openapi specifications related to integrations have been tagged with the <code>institution integration</code> label within the openapi specification.</p> <ul> <li>Opal-Backend: Swagger rendering at {hostAddress}/api/schema/swagger-ui</li> <li>Opal-Admin: openapi.yml</li> <li>Opal-Labs: openapi.yml</li> <li>Opal-RMS: openapi.yml</li> </ul>"},{"location":"deploy/integration/#requirements-for-hospital-endpoints","title":"Requirements for Hospital Endpoints","text":"<p>In addition to the endpoints Opal provides for data integration, there are also a small number of endpoints that need to be made available to the Opal application layer to facilitate the full range of Opal functionality. These endpoints should provide information like patient demographics, historical data retrieval, and patient location updates (for hospitals that have chosen to enable the <code>Opal-RMS</code> service).</p> <p>We also provide an openapi specification roughly outlining what these endpoints should look like.</p>"},{"location":"development/","title":"Contribute to development","text":"<p>TBD</p>"},{"location":"development/setup/","title":"Set up a local development environment","text":"<p>The following instructions will guide you through the process of setting up Opal locally on your machine. This guide is split into several aspects of the Opal solution because some components are less frequently worked on.</p>"},{"location":"development/setup/#required-software","title":"Required software","text":"<p>In general, all projects with the exception of one project (the mobile app) are containerized. Therefore, the required software to be installed on your machine directly is fairly small.</p> <ul> <li>Git for version control</li> <li>Git Large File Storage (LFS), used in some projects to version large files</li> <li>Docker Desktop<sup>1</sup></li> <li>An IDE, such as Visual Studio Code</li> <li>Node.js to build and run the mobile app (as a web app)</li> </ul> Note about <code>node</code> <p>We strongly recommend installing node via the Node Version Manager (nvm) (nvm for macOS, nvm for Windows). It makes it possible to install different node versions, quickly switch between different versions, and makes updating Node painless.</p>"},{"location":"development/setup/#supported-operating-systems","title":"Supported operating systems","text":"<p>As our team uses macOS (Apple Silicon) and Windows machines, we strive to support both these operating systems for local development.</p>"},{"location":"development/setup/#set-up-main-components","title":"Set up main components","text":"<p>The components most frequently being worked on are the user and clinical staff facing ones. Therefore, the following instructions focus on these components. The other components are considered optional.</p> <p>Clone repositories using the GitLab CLI</p> <p>Instead of cloning repositories \"manually\" by copying their git URL from the project page and cloning it via <code>git clone</code> it is also possible to use the GitLab CLI to do so.</p> <p>The CLI provides the <code>repo clone</code> command to clone repositories. Note that if you clone all repositories of a group you will clone more repositories than you actually need.</p>"},{"location":"development/setup/#set-up-your-own-firebase-project","title":"Set up your own Firebase project","text":"<p>The user applications communicate via Firebase with the Opal PIE. You need your own Firebase project so that your local app can communicate with the backend components.</p> <p>Note</p> <p>Firebase is a Google product. Therefore, you need a Google account to be able to use Firebase.</p>"},{"location":"development/setup/#create-a-new-firebase-project","title":"Create a new Firebase project","text":"<ol> <li>Open the Firebase Console</li> <li>Click on \"+ Add project\"</li> <li>Give it a relevant project name, such as \"Opal Local\"</li> <li>Uncheck \"Enable Google Analytics for this project\"</li> <li>Click \"Create project\"</li> </ol> <p>The \"Authentication\" and \"Realtime Database\" features are needed for communication between the apps and backend components. Follow the instructions below to enable and configure these features.</p>"},{"location":"development/setup/#create-a-new-realtime-database","title":"Create a new Realtime Database","text":"<ol> <li>In the left panel of your newly created Firebase project, expand \"Build\" and click on \"Realtime Database\".</li> <li>Click \"Create Database\"</li> <li>On the second step of \"Set up database\" (Security rules), select \"Start in test mode\".</li> </ol> <p>Note</p> <p>This configures your Realtime Database to be accessible to anyone for 30 days. It is also possible to restrict access to authenticated users only by specifying the condition as <code>auth.uid !== null</code>. However, not all features will work. The rules in use by the Opal solution can be found in the listener project. See the instructions on how to deploy them to your project or copy-and-paste them into your project's rules.</p> <p>See also the Firebase documentation on Firebase Security Rules.</p>"},{"location":"development/setup/#enable-email-and-password-authentication","title":"Enable email and password authentication","text":"<ol> <li>In the left panel, expand \"Build\" and click on \"Authentication\"</li> <li>Click on \"Get started\"</li> <li>Choose \"Email/Password\" as the sign-in provider</li> <li>Enable \"Email/Password\" and click \"Save\"</li> </ol> <p>See also the Firebase documentation on Firebase Authentication.</p>"},{"location":"development/setup/#retrieve-the-firebase-project-configurations","title":"Retrieve the Firebase project configurations","text":"<p>Retrieve the client configuration:</p> <ol> <li>Click on the settings icon (gear) next to \"Project Overview\"</li> <li>Click on \"Project Settings\"</li> <li>In the \"General\" tab, under \"Your Apps\", click the \"&lt;/&gt;\" icon</li> <li>Choose an app nickname, such as \"Opal Local\"</li> <li>Click \"Register app\"</li> <li>Copy the code and save it somewhere for later</li> </ol> <p>Retrieve the private key for the admin SDK:</p> <ol> <li>Go back to the \"Project Settings\" page and click on the \"Service accounts\" tab</li> <li>Click on \"Generate new private key\" and then \"Generate key\"</li> <li>Download the file somewhere safe on your machine for later</li> </ol> <p>See also the Firebase documentation on Admin SDK Authentication.</p>"},{"location":"development/setup/#set-up-the-legacy-databases","title":"Set up the legacy databases","text":"<p>All legacy databases are managed using Alembic. Follow the instructions in the db-docker README to set them up.</p> <p>Ensure that you also insert the test data via the <code>reset_data.sh</code> script as outlined in the instructions.</p>"},{"location":"development/setup/#set-up-the-backend","title":"Set up the backend","text":"<p>Follow the backend README to set it up.</p> <p>In addition, there are management commands that initialize required data as well as test data.</p> <p>Run the following management commands on the backend:</p> <pre><code>python manage.py initialize_data\npython manage.py insert_test_data OMI\n</code></pre> <p>See the command's help to learn about all options.</p> <p>The <code>initialize_data</code> command generates authentication tokens for system users that are needed for configuring other components via their environment files.</p> <p>Then, migrate all opalAdmin users to the backend.</p> <pre><code>python manage.py migrate_users\n</code></pre> <p>Then, set the password of the user <code>admin</code> to a password of your choice.</p> <pre><code>python manage.py changepassword admin\n</code></pre>"},{"location":"development/setup/#set-up-the-listener","title":"Set up the listener","text":"<p>Follow the instructions outlined in the listener README to set it up.</p> <p>Once the listener is running, initialize the test users in Firebase with the initialize_users script:</p> <pre><code>docker compose exec app node src/firebase/initialize_users.js\n</code></pre> <p>The script creates several test users all with the same password (see the script).</p>"},{"location":"development/setup/#set-up-opaladmin","title":"Set up opalAdmin","text":"<p>Follow the instructions outlined in the opalAdmin README to set it up.</p> <p>Once it is running you can log in with the user <code>admin</code> and the password you set above when setting up the backend.</p>"},{"location":"development/setup/#set-up-the-mobile-app","title":"Set up the mobile app","text":"<p>Follow the instructions outlined in the mobile app README.</p>"},{"location":"development/setup/#optional-user-registration","title":"Optional: User Registration","text":"<p>Setting up the above components will give you the ability to use the mobile app and manage clinical data (such as questionnaires,  appointment descriptions etc.) with opalAdmin.</p> <p>If you need to create new user accounts you can set up the user registration as well. Follow the instructions in the registration README.</p>"},{"location":"development/setup/#other-components","title":"Other components","text":"<p>Setting up the above components will give you the ability to use the mobile app, manage clinical data, and register new caregivers so that they can access a patient's data.</p> <p>All other components as outlined in the component overview are only necessary if you want to contribute to that component specifically. Follow the README in any project to set it up, and update the respective environment variables in other components that make API calls to it.</p> <ol> <li> <p>You are welcome to use another container engine. However, all the commands shown in our instructions are specific to  <code>docker</code> and <code>docker compose</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/architecture/","title":"Architecture","text":"<p>Opal is a solution aimed at providing patients and their caregivers<sup>1</sup> access to the patient's medical data. Opal provides two main parts to achieve this goal:</p> <ol> <li>A patient/caregiver-facing part to give them access to the medical data.</li> <li>A clinical staff facing part to manage the patient data.</li> </ol> <p>Note</p> <p>The diagrams presented here are based on the C4 model for visualizing software architecture. They are created with PlantUML using the C4 PlantUML Extension.</p> <p>We use system context and container diagrams. Note that a container represents an application or data store (and not a \"Docker container\"). In this document we use container and component interchangeably.</p>"},{"location":"development/architecture/#high-level-architecture","title":"High-level Architecture","text":"<p>The following system context diagram shows a high-level view of the architecture.</p> <p></p> <p>The Opal solution provides the Opal Patient Information Exchange (PIE) which is currently deployed inside a hospital. The components accessible by caregivers are available via mobile app stores and are also hosted on the web. These components consist of the user registration web application to create user accounts and the application for patients (or their caregiver(s)) to access the patient's medical data.</p>"},{"location":"development/architecture/#overview-of-user-applications","title":"Overview of User Applications","text":"<p>The following container diagram focuses on the user applications that users (caregivers) use with Opal.</p> <p></p> <p>As can be seen in the above diagram, communication between the user applications and the Opal PIE is accomplished via Firebase.</p> <p>The User Registration currently only supports user account creation by requesting access to a patient's data. The user will receive a registration code at the end of this process which is required on the User Registration.</p>"},{"location":"development/architecture/#overview-of-the-opal-pie","title":"Overview of the Opal PIE","text":"<p>The following container diagram shows the Opal PIE.</p> <p></p> <p>The diagram presents the Opal PIE as it is today.</p>"},{"location":"development/architecture/#future-vision","title":"Future Vision","text":"<p>Recently, we have started with a process to migrate functionality to a new component (Backend). The functionality provided by components marked as legacy will be migrated to the backend over time. We are following the Strangler Fig migration pattern for this process.</p> <p>The vision is that the backend will be a majestic monolith. The following diagram depicts this vision.</p> <p></p> <p>Note that additional external systems were left out for brevity.</p>"},{"location":"development/architecture/#overview-of-components","title":"Overview of components","text":"<p>The following is an overview of all the components that are part of the Opal solution.</p>"},{"location":"development/architecture/#opal-integration-engine-oie","title":"Opal Integration Engine (OIE)","text":"<ul> <li>Project Page</li> <li>Mirth Connect</li> </ul> <p>The OIE is responsible for interfacing with the hospital's interface. It receives unsolicited HL7 messages from hospital source systems. It also makes solicited requests to source systems in the hospital. For example, to search for a patient in the hospital (that is not a patient in Opal yet), or, to send data, such as a PDF that should be stored in the patient's chart in the hospital system. For the latter case, the OIE provides a set of API endpoints for our components to make requests to hospital systems.</p> <p>Note</p> <p>This component is currently specific to the McGill University Health Centre (MUHC) where this is used in production. Future work needs to establish a generic approach that can be adapted for other hospitals. Furthermore, some hospital systems do not send data in real time. Instead, they provide APIs to retrieve data instead. More work is required to support both these scenarios.</p>"},{"location":"development/architecture/#opaladmin","title":"OpalAdmin","text":"<ul> <li>Project Page</li> </ul> <p>OpalAdmin provides the admin interface for clinicians and staff. The web application is used to manage patients, hospital maps, questionnaires etc. It exposes all of its functionality via an API. Most of the API is intended for the frontend which is built as a single page application. The remaining parts of the API are intended for use by our other components, such as the OIE.</p> <p>OpalAdmin also contains a publishing module which contains scripts that are run periodically. These scripts manage new data that was added, and determine whether caregivers need to be informed about new patient data (via push notifications to their mobile devices).</p>"},{"location":"development/architecture/#listener","title":"Listener","text":"<ul> <li>Project Page</li> <li>Published Documentation</li> </ul> <p>The listener is the component that interacts with Firebase in order to handle requests coming from the user applications. The requests it handles are those intended for the hospital the Opal PIE is operating in. See the section on communication below for more information.</p> <p>The listener contains legacy app and registration functionality as well as new functionality for forwarding API requests to the backend:</p> <ul> <li>The legacy part handles request types and directly executes queries on the databases.</li> <li>The new functionality receives API requests (basically, HTTP requests as JSON) and forwards them to the backend API.   It acts as a kind of proxy/middleware and makes actual HTTP requests.   The HTTP response is returned.</li> </ul>"},{"location":"development/architecture/#backend","title":"Backend","text":"<ul> <li>Project Page</li> <li>Published Documentation</li> </ul> <p>The backend (aka. New OpalAdmin) is the new backend that replaces the legacy OpalAdmin. It provides APIs for the user applications and other systems, such as the OIE. In addition, it provides the new user interface for OpalAdmin containing all the new functionality, auditing, user authentication and authorization.</p> <p>Over time, other existing functionality will be migrated to this component (see future vision).</p>"},{"location":"development/architecture/#opal-labs","title":"Opal Labs","text":"<ul> <li>Project Page</li> </ul> <p>Opal Labs is an additional component which takes care of processing new lab results for patients. It exposes an API endpoint for use by the OIE to handle new lab results. Opal Labs takes care of inserting those lab results into the database (<code>OpalDB</code>). It also makes an API call to OpalAdmin to request sending a push notification to caregivers.</p> MUHC Specifics <p>Opal Labs also contains an API endpoint to retrieve the lab result history for a particular patient. The endpoint calls the VSign SOAP web service of OACIS to retrieve the history. This action is performed when a new patient is added to Opal at the end of the registration process. It is triggered by the OIE.</p>"},{"location":"development/architecture/#user-registration","title":"User Registration","text":"<ul> <li>Project Page</li> <li>Production Registration</li> </ul> <p>The registration websites provides a user (caregiver) the ability to create their Opal account. In order to use the registration website, a caregiver has to request access to a patient's data at the hospital. At the end of this, the hospital will provide a registration code to the caregiver. Using the registration code and the patient's identification number (RAMQ or MRN) the user can complete the registration process.</p>"},{"location":"development/architecture/#web-and-mobile-app","title":"Web and Mobile App","text":"<ul> <li>Project Page</li> </ul> <p>The web and mobile app provide caregivers the ability to access patient data for the patients under their care. The mobile app is the same as the web app. It is packaged as a mobile app and distributed through the Google Play and Apple App stores. The mobile app supports additional features native to mobile devices, such as location, sharing etc.</p>"},{"location":"development/architecture/#helper-components","title":"Helper components","text":""},{"location":"development/architecture/#database-migrations-and-initial-data","title":"Database Migrations and Initial Data","text":"<ul> <li>Project Page</li> </ul> <p>Historically, the legacy components of Opal did not maintain migrations of the database schema. Migrations and initial data (to set up Opal at a new hospital) is maintained in this separate component. The migrations are managed using Alembic. Initial data and upgrade scripts are maintained as SQL files.</p> <p>A container image is produced for this component. It is only necessary to run this during setup and upgrade.</p>"},{"location":"development/architecture/#third-party-components","title":"Third-party components","text":""},{"location":"development/architecture/#redis","title":"Redis","text":"<ul> <li>Project Page</li> </ul> <p>Redis is used by Opal Labs to cache patients being processed to avoid sending caregivers multiple push notification times when batch processing.</p>"},{"location":"development/architecture/#communication-between-user-applications-and-the-opal-pie","title":"Communication between user applications and the Opal PIE","text":"<p>Hospital networks are typically not accessible from the outside. Firebase is used to support passing data from within the hospital firewall to the user applications and vice versa.</p> <p>Opal makes use of two Firebase services:</p> <ul> <li>Authentication is used for user accounts (via email and password).</li> <li>Realtime Database is used to pass requests and responses between user applications and the Opal PIE.</li> </ul> <p>A Firebase user account is created when a user completes the user registration for the first time. The Firebase Realtime Database acts as a kind of queue for sending requests and receiving responses.</p> <p>The Opal PIE establishes an outgoing connection to Firebase to observe the Realtime Database for changes. Any time a new request is added by a user application it is notified of this change and handles the request. The response for the request is placed into the Realtime Database and the user application\u2013which is notified of the response\u2013reads and handles the response.</p>"},{"location":"development/architecture/#encryption","title":"Encryption","text":"<p>TBC</p>"},{"location":"development/architecture/#supporting-multiple-hospitals","title":"Supporting Multiple Hospitals","text":"<p>TBC</p> <p>https://gitlab.com/opalmedapps/qplus</p>"},{"location":"development/architecture/#appointment-checkin-processes","title":"Appointment Checkin Processes","text":"<p>A core functionality within the Opal ecosystem is the ability for a patient (or a caregiver of a patient) to checkin to an appointment at the hospital. There are several different ways this can happen, depending on whether the Opal Wait Room Management System has been installed at the hospital or not, and whether the hospital system itself tracks appointment checkins.</p>"},{"location":"development/architecture/#opal-app-checkins","title":"Opal App Checkins","text":"<p>When a user logs into the Opal application, they can see right away if they have any scheduled appointments for that day in the app home screen. By default, an appointment can only be checked in from the app if the user is located at or near the hospital site where the appointment is scheduled.</p> <p>Currently, when a user attempts to login for themselves or for a patient under their care, all appointments for that day will be attempted to be checked in at once. The Listener container receives this request and is responsible for making all necessary API calls to successfully check the patient in for that day's appointments.</p> <p>Configuration variables within the Listener environment control whether the listener will attempt to notify ORMs and/or the Hospital Source System of this patient checkin. The Opal Backend is always notified of a patient checkin.</p> <p>The following sequence diagram details the series of API calls that are made immediately after a patient clicks the Check In button from the Opal app.</p> <p></p> <p>Note that a checkin is only considered \"successful\" if all attempted checkin API calls to the various checkin systems were successful. In addition, under the \"all appointment checkin for a day\" paradigm, a single failed appointment checkin will result in displaying an error message to the patient indicating that all checkins have failed.</p>"},{"location":"development/architecture/#opal-wait-room-management-system-checkins","title":"Opal Wait Room Management System Checkins","text":"<p>The Opal Wait Room Management system will be notified of Opal app checkins as shown in the sequence diagram above. However, ORMs also provides several additional methods of checking in to an appointment for patients.</p> <p>These are:</p> <ul> <li>Kiosk Checkins - where a patient can scan their hospital card at an ORMs kiosk in the hospital to checkin to all appointments for the day, before proceeding to the waiting room</li> <li>Virtual Waiting Room (VWR) Checkins - where a patient can request to be checked into all appointments for that day at a reception desk, and a clinical staff member uses the ORMs VWR to perform the checkin on the patient's behald</li> <li>SMS Checkins - where a patient can respond to an automated SMS received to their mobile device with the phrase 'Check In' in order to be checked in for all appointments for the day</li> </ul> <p>From the perspective of the Opal ecosystem, all three of these checkin methods are identical in that they result in the same API call(s) from ORMs to Opal, although from a patient perspective they are different.</p> <p>The following sequence diagram details the series of API calls that are made immediately after a patient attempts a checkin from a wait room Kiosk, from their phone SMS, or via a clinical staff member interacting with the ORMs virtual waiting room.</p> <p></p> <ol> <li> <p>We consider a caregiver to also include the patient. In that case they are caring for themself.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/architecture/migration/","title":"Migration","text":"<p>The Opal solution has organically evolved over time since its inception. In order to simplify the architecture and reduce accidental complexity we started a process to migrate functionality in legacy components over time to the backend (using Python and the Django web framework). At the same time, this helps to move away from old technology. See the high-level architecture for more details on the current architecture and future vision.</p>"},{"location":"development/architecture/migration/#migrating-legacy-components-using-the-strangler-fig-pattern","title":"Migrating Legacy Components using the Strangler Fig Pattern","text":"<p>We are using the Strangler Fig Pattern in order to move from the legacy components of Opal to new components and a new architecture in an incremental way.</p> <p>This approach provides an alternative to building a completely new system from scratch and doing a complete switch over once it is fully completed. Instead, the new system is built and operated in parallel and new functionality is only added to the new system. The new system is incrementally built and the old system eventually strangled.</p> <p>More details about this pattern can be found in the resources below.</p>"},{"location":"development/architecture/migration/#resources","title":"Resources","text":"<ul> <li>Strangler Fig Application - Martin Fowler</li> <li>How Shopify applied the Strangler Fig Pattern within the same codebase: Refactoring Legacy Code with the Strangler Fig Pattern</li> </ul>"},{"location":"development/architecture/migration/#additional-articles-about-strangler-fig-pattern","title":"Additional articles about Strangler Fig Pattern","text":"<ul> <li>Paper: An Agile Approach to a Legacy System</li> <li>Legacy Application Strangulation: Case Studies</li> <li>The Strangler Fig Migration Pattern | by Diana Darie | Medium</li> <li>The Strangler pattern in practice - Michiel Rook's blog</li> <li>What is the Strangler Fig Pattern and How it Helps Manage Legacy Code</li> <li>The Ship of Theseus to NOT rewrite a legacy system from scratch</li> <li>https://docs.microsoft.com/en-us/azure/architecture/patterns/strangler-fig</li> </ul>"},{"location":"development/architecture/migration/#migration-process","title":"Migration Process","text":"<p>As outlined in the future vision the goal is that all functionality will be migrated to the Backend component. The backend is operated in parallel and was established to provide new functionality, such as hospital settings, caregivers and their relationships to patients, caregiver management, email verification for the registration etc.</p> <p>Before the migration process began, Opal only supported a one-to-one relationship between a patient and user. Patient and user are tightly connected concepts in the legacy system. For instance, the <code>Patient</code> table in the <code>OpalDB</code> database contains several user-specific columns and a <code>Users</code> record always links to a <code>Patient</code> record. The reliance in the legacy codebase on both of these in combination makes it more difficult to completely remove the <code>Users</code> table right away. In addition, patients are the most important concept as all data and relationships are tied to a patient. During the initial phase of the migration process, there is some duplicated data required to be held in both the legacy system and the backend.</p>"},{"location":"development/architecture/migration/#data-overview","title":"Data Overview","text":"<p>The following table shows data that exists in both systems. Legacy refers to the legacy backend (stored in the legacy database OpalDB) and Backend for the new backend.</p> Concept Legacy Backend Patient <code>Patient</code> table: Contains all patients and a dummy patient entry for users who are not patients themselves. <code>Patient</code> model: Contains all patients with a <code>legacy_id</code> referring to <code>Patient.PatientSerNum</code> in the legacy DB. Caregiver User <code>Users</code> table: Contains all users. The <code>UserType</code> is <code>Patient</code> if the user is also a patient and <code>Caregiver</code> if it is a caregiver only. The <code>Caregiver</code> model is a type of <code>User</code> which contains all existing (migrated) and new caregiver users. The <code>CaregiverProfile</code> model links to it and adds the <code>legacy_id</code> which refers to <code>Users.UserTypeSerNum</code>. Hospital Site <code>Hospital_Identifier_Type</code> table: Contains sites of a hospital and their internal code. <code>Institution</code> and <code>Site</code> models: Contains institutions and their site(s) along with their properties and settings. Hospital Patient <code>Patient_Hospital_Identifier</code> table: Contains the list of MRNs and site codes <code>HospitalPatient</code> model: Contains the list of MRNs and a reference to the <code>Site</code> instance Security Question Deprecated: <code>SecurityQuestion</code> table: Contains a list of pre-defined security questions <code>SecurityQuestion</code> model: Contains a list of (migrated) pre-defined security questions Security Answer Deprecated: <code>SecurityAnswer</code> table: The answer to a particular question <code>SecurityAnswer</code> model: The answer to the question. The question is a field within the same model to support user-defined questions in the future. Device <code>PatientDeviceIdentifier</code>: Still in use as a cache for the listener to keep session data <code>Device</code> model: Currently unused User (Staff) <code>OAUser</code> table: Contains all users who can log in to OpalAdmin The <code>ClinicalStaff</code> model is a type of <code>User</code> which contains all users."},{"location":"development/architecture/migration/#diagrams","title":"Diagrams","text":"<p>The following diagrams were initially produced using the Django app <code>django-model2puml</code>.</p>"},{"location":"development/architecture/migration/#opaldb-legacy","title":"OpalDB (Legacy)","text":"<p>Some of the tables shown are an excerpt and do not contain all columns (denoted with <code>...</code> at the bottom).</p> <p></p>"},{"location":"development/architecture/migration/#backend","title":"Backend","text":""},{"location":"development/architecture/migration/#keeping-data-in-sync","title":"Keeping Data in Sync","text":"<p>Keeping the same data in two places has the risk that the data runs out of sync. In order to keep the data in sync between both there are management commands in the backend that can migrate data from the legacy system over. Most commands are intended to be run only once to migrate data during an upgrade. There also exist management commands that check for deviations (for patients and caregivers). These commands are run periodically.</p>"},{"location":"development/architecture/migration/#maintaining-user-session-data","title":"Maintaining User Session Data","text":"<p>For certain tasks, such as logging in, decryption of requests and encryption of responses, the listener needs access to certain data (such as the current session encryption key). The table <code>PatientDeviceIdentifier</code> in the legacy database (<code>OpalDB</code>) contains various session data and acts as some kind cache/session store where data related to the user's session is stored. Since the listener already accesses this data, we can use this table to store session-related data in the short term.</p> <ul> <li> <p>Keep the <code>PatientDeviceIdentifier</code> table as a cache for the listener</p> <ul> <li>Store the Firebase username as a reference to the user (available with every request)</li> <li>Store the current security answer hash</li> <li>Maintain the current use of storing the device and push IDs</li> </ul> </li> </ul> <p>Over time we can then fully move it to the backend and cache required session data in the listener directly.</p>"},{"location":"development/architecture/migration/#path-forward","title":"Path Forward","text":"<p>There is still a lot of functionality to be migrated. More investigation is required to determine the exact migration path forward.</p>"},{"location":"development/architecture/registration/","title":"Registration Process","text":""},{"location":"development/architecture/registration/#requesting-access-to-patient-data-aka-opal-registration-aka-qr-code-generation-aka-access-request","title":"Requesting access to patient data (aka. Opal Registration aka. QR Code Generation aka. Access Request)","text":"<p>This reflects the currently envisioned flow with the new OpalAdmin/Backend.</p> <pre><code>sequenceDiagram\n\n    actor Clerk\n    participant FE as OpalAdmin v2\n    participant BE as Backend\n    participant DB as New DB\n    participant OIE\n\n    Clerk -&gt;&gt; FE: search patient\n    FE -&gt;&gt; OIE: search patient by MRN/RAMQ\n    FE -&gt;&gt; Clerk: show search result\n    Clerk -&gt;&gt; FE: provide relationship details\n\n    alt new user\n        Clerk -&gt;&gt; FE: provide name of user\n        %% Clerk -&gt;&gt; FE: request code generation\n    else existing user\n        Clerk -&gt;&gt; FE: search for existing user\n        FE -&gt;&gt; BE: look up user\n        FE -&gt;&gt; Clerk: provide search result\n        %% Clerk -&gt;&gt; FE: request access\n    end\n\n    Clerk -&gt;&gt; FE: request generate QR code/add access\n    FE -&gt;&gt; BE: handle request\n    opt patient does not exist yet\n        BE -&gt;&gt; DB: insert minimal patient data\n    end\n    opt user does not exist yet\n        BE -&gt;&gt; DB: insert minimal user data\n    end\n    BE -&gt;&gt; DB: insert relationship request details\n    opt new user\n        BE -&gt;&gt; BE: generate registration code\n        BE -&gt;&gt; DB: insert registration code\n    end\n    BE -&gt;&gt; FE: result\n    FE -&gt;&gt; Clerk: result</code></pre>"},{"location":"development/architecture/registration/#registration-web-page-encryptiondecryption","title":"Registration Web Page Encryption/Decryption","text":"<p>The encryption/decryption details are omitted in the diagram in the next section for brevity. The following diagram provides these details.</p> <pre><code>sequenceDiagram\n\n    participant FE as Web Page\n    participant BE as Listener\n    participant API as New Backend\n\n    FE -&gt;&gt; FE: encrypt with PBKDF2(key=code, salt=RAMQ)\n    FE -&gt;&gt; BE: send request via Firebase\n    note right of FE: request contains SHA512(code)\n    BE -&gt;&gt; API: get registration details for hashed code\n    note right of API: patient health insurance number and list of MRNs\n    loop until correct salt found\n    BE -&gt;&gt; BE: decrypt request using code and current data\n    note right of BE: remember correct salt\n    end\n    note right of BE: handle request\n    BE -&gt;&gt; BE: encrypt response with PBKDF2(key=code, salt=correct_salt)\n    BE --&gt;&gt; FE: send response via Firebase</code></pre>"},{"location":"development/architecture/registration/#using-the-registration-web-page","title":"Using the registration web page","text":"<p>This reflects the currently envisioned flow with the new OpalAdmin/Backend via the listener's new API request functionality.</p> <p></p>"},{"location":"development/best_practices/best_practices/","title":"Software Engineering Best Practices","text":"<p>The purpose of this document is to provide an overview of the software engineering principles and best practices used and enforced at O-HIG for all development. For changes to legacy code that did not adhere to these standards, exceptions can be made.</p> <p>Automating tasks to check/enforce these principles should be used wherever possible. This relieves the developers (code reviewers) from these tedious tasks and allows them to focus more on the business logic, implementation etc.</p> <p>Any best practice outlined in this document should come with a rationale on why it is important:</p> <p>\u201cGood advice comes with a rationale so you can tell when it becomes bad advice. If you don\u2019t understanding why something should be done, then you\u2019ve fallen into the trap of cargo cult programming, and you\u2019ll keep doing it even when it\u2019s no longer necessary or even becomes deleterious.\u201d</p> <p>\u2014 Raymond Chen at The Old New Thing</p>"},{"location":"development/best_practices/best_practices/#version-control","title":"Version Control","text":"<p>Everything relating to a certain project needs to be version controlled in the corresponding repository. This serves as the single source of truth.</p> <p>Everything that is text-based should be version controlled. Besides source code itself this includes Docker files, CI/CD files, bash scripts, backup scripts, documentation, translations etc.</p> <p>Each repository should have a <code>.gitignore</code> (to ignore any unnecessary files, e.g., OS-specific ones. See collection of gitignore templates) and <code>.gitattributes</code> file (to tell Git how to handle line endings, binary files, LFS etc. see why this is necessary and a collection of useful templates).</p>"},{"location":"development/best_practices/best_practices/#documenting-changes-and-decisions","title":"Documenting Changes and Decisions","text":"<p>Everything that is not part of the repository (\u201cthe single source of truth\u201d), such as results of discussions, decisions and changes etc., should be documented in the corresponding issue. This provides traceability for the future, not just for other developers but also for your future self.</p> <p>To that effect, commits should reference the corresponding issue the commit is made for.</p> <p>Note</p> <p>Jira and GitLab should be connected in order to facilitate this: https://docs.gitlab.com/ee/integration/jira/issues.html (see also: https://about.gitlab.com/solutions/jira/)</p>"},{"location":"development/best_practices/best_practices/#commit-style","title":"Commit Style","text":"<p>Good commit messages matter:</p> <p>\u201ca well-crafted Git commit message is the best way to communicate context about a change to fellow developers (and indeed to their future selves). A diff will tell you what changed, but only the commit message can properly tell you why.\u201d</p> <p>\u2014 cbeams via How to Write a Git Commit Message</p> <p>Make commits after each logical change (or select those changes that form a logical change). This also makes it easier to explain the change in the commit message. Never just blindly add the whole file to commit to avoid adding temporary code. Make use of visual Git tools or the integration within the IDE and leverage the Git index (staging). I.e., use the diff to select those changes in a file that relate to the change you are about to commit.</p> <p>Reference the issue the commit relates to. This helps in the future when dealing with bugs or generally when determining why a certain change in the code was made.</p>"},{"location":"development/best_practices/best_practices/#resources","title":"Resources","text":"<ul> <li>How to Write a Git Commit Message</li> <li>Commit Often, Perfect Later, Publish Once\u2014Git Best Practices</li> </ul>"},{"location":"development/best_practices/best_practices/#code-style","title":"Code Style","text":"<p>All code needs to follow a commonly decided code style. Each language has a code style that is agreed upon (see language specific sections below).</p> <p>If you have a strong opinion/preference about something you disagree with in the code style, bring it up to the team and discuss the rationale.</p>"},{"location":"development/best_practices/best_practices/#comments","title":"Comments","text":"<p>Comments provide documentation about what a piece of code is supposed to do, how to call it and what could happen. It helps your future self and other developers.</p> <p>All classes, functions/methods and constants (whether they are public or private) need to be documented using the corresponding documentation standard of the language (e.g., JavaDoc, JSDoc, Python Docstring etc.). Doing so provides the ability to generate documentation documents that provide an overview of the functionality of the code base. Private functionality also needs documentation in order to help developers understand.</p> <p>Comments within the code itself should only be added if additional context is required. For example, to clarify why something is done or if it\u2019s not obvious right away/quite complex.</p>"},{"location":"development/best_practices/best_practices/#documentation","title":"Documentation","text":"<p>A documentation document should be generated containing prose and API reference. The documentation text should reside within the repository as well (i.e., version controlled and part of the overall development process).</p> <p>As part of the CI/CD process the live documentation needs to be generated and made available in a place where it is accessible by all developers.</p> <p>Whenever new functionality is added or existing functionality modified, the specification documentation needs to be extended/updated.</p>"},{"location":"development/best_practices/best_practices/#testing","title":"Testing","text":"<p>Unit tests need to be written for most of the code. This can be done before making the change, after making the change or during. The tests should not only cover one (successful) code path but the goal is to achieve branch coverage and test for different inputs and error conditions. While you design your code, think about all the different ways this could be called, what should be considered and what could potentially go wrong (and test for those).</p> <p>TODO/TBD</p> <p>Integration tests, UI tests, smoke tests, \u2026?</p>"},{"location":"development/best_practices/best_practices/#continuous-integration-ci-and-delivery-cd","title":"Continuous Integration (CI) and Delivery (CD)","text":"<p>Each repository needs to have a pipeline (or several) defined that runs the different steps (linting, type checking, tests, coverage, building Docker images etc.) each time someone pushes to the repository.</p> <p>Continuous Delivery should be used to automatically deploy the changes to a testing environment.</p>"},{"location":"development/best_practices/best_practices/#code-review","title":"Code Review","text":"<p>Code Review is an important part of the development process. It helps share knowledge and ownership among developers. Doing code review also helps reduce bugs and ensure a consistent codebase for long-term maintainability. Please see our Code Review Guidelines for more details.</p> <p>A comprehensive guide on providing good code review is available at Google's Engineering Practices documentation.</p> <p>The following principles taken from the above guide are especially important to follow:</p> <ol> <li> <p>Fast response time</p> <p>The code review process is meant to improve the quality of new code. However, if the process becomes too frustrating to developers, it can have the opposite effect by becoming an obstacle against making valuable changes.</p> <p>The total code review process can be as fast or as slow as needed, but the delay between each reply should be as short as possible. It should take a day (or at most a few days) to submit your first comments, and the participants should reply to new commits or messages as soon as possible (but without interrupting focused work).</p> <p>A fast response time is important because \"most complaints about the code review process are actually resolved by making the process faster\", and since \"slow reviews also discourage code cleanups, refactorings, and further improvements\".</p> </li> <li> <p>Improved quality</p> <p>Code review involves using time and effort to improve the quality of new code, but also requires choosing a stopping point at which to integrate changes into the project and ensure forward progress.</p> <p>You must balance between your responsibility to ensure good code quality, and the need to allow developers to make progress. Don't allow code to be integrated that reduces the overall quality of the system (unless in an emergency). That being said, code review must end at some point. A good rule of thumb is that \"reviewers should favor approving a CL [changelist] once it is in a state where it definitely improves the overall code health of the system being worked on, even if the CL isn\u2019t perfect.</p> </li> <li> <p>Giving clear expectations</p> <p>Clear communication helps code reviews to go more smoothly and be more effective. Here are some examples of things that should be communicated:</p> <ul> <li>If you're holding off on approving changes until something specific is done, let the author know so you aren't both left in an uncertain waiting state.</li> <li>Identify any suggestions that you want to leave up to the developer to accept or ignore (take it or leave it) and for which you don't expect follow-up.     These are suggestions that the author can ignore if they choose to.</li> <li>You can identify small detail changes, often style-related, as \"nit:\" (representing a nit-pick).</li> <li>Let the author know if you were only able to review one aspect of a changelist.     For example, if you reviewed database changes but someone else needs to review the security aspect of those changes, let the author know.</li> </ul> </li> </ol>"},{"location":"development/best_practices/best_practices/#branching-style","title":"Branching style","text":"<p>A very common branching model is git flow (main, develop, feature and hotfix branches). Very popular is also GitHub Flow (main and feature/hotfix branches) which treats main as always deployable.</p> <p>Git Flow has additional complexity which is worth it in some cases (see Workflows Comparison: Git Flow Vs GitHub Flow).</p> <p>GitLab Flow is a simpler version of Git Flow.</p> <p>Proposal: Start with the simple model (GitHub Flow) and see if that is sufficient. Unless we have strong reasons to use a more complex model due to the way we deploy.</p>"},{"location":"development/best_practices/best_practices/#merging","title":"Merging","text":"<p>Developers have different opinions on merging, rebasing and squashing and there are pros and cons for each. Because of this it makes sense to provide common guidelines on when to use which merge strategy.</p> <p>When following the practice of \u201ccommit early, commit often\u201d and making commits with logical changes (see Commit Style) having the progress of a feature change visible through these commits can still be beneficial in the future. For example, Git provides the ability to use binary search to find the commit that introduced a bug (<code>[git bisect](https://git-scm.com/docs/git-bisect)</code>). This is easier to accomplish the smaller the changes are that a commit adds.</p> <p>In general, there are explicit merges, fast-forward merges and \u201csquash on merge\u201d. A great visualization of these is provided in the article Pull Request Merge Strategies: The Great Debate - Atlassian Developer Blog and a debate on pros and cons can be found at Git team workflows: merge or rebase? | Atlassian Git Tutorial</p> <p>TBD</p> <p>Use squash merge vs. merge commit</p>"},{"location":"development/best_practices/best_practices/#merging-resources","title":"Merging Resources","text":"<ul> <li>Pull Request Merge Strategies: The Great Debate - Atlassian Developer Blog</li> <li>Git team workflows: merge or rebase? | Atlassian Git Tutorial</li> <li>Two years of squash merge - DNSimple Blog</li> </ul>"},{"location":"development/best_practices/best_practices/#containerization","title":"Containerization","text":"<p>Each component should be containerized, i.e., a Dockerfile needs to be defined. Ensure that also a .dockerignore file is provided to exclude any unwanted data to be added to the container image. This also speeds up the process of building an image (e.g., when the <code>.git</code> directory is excluded).</p> <p>For local development, provide a Compose file.</p> <p>Containerizing components allows reproducible builds (no more \u201cworks on my machine\u201d) and they can be used in all steps of the development process (locally, CI, deployment etc.). Furthermore, the Dockerfile in a way documents the dependencies that are required for a component to be run (e.g., a certain system package to connect to a DB).</p> <p>Containers should be modular, i.e., one container per component (single responsibility principle).</p> <p>Best practices for Dockerfiles: See below.</p>"},{"location":"development/best_practices/best_practices/#dependency-management","title":"Dependency Management","text":"<p>Any dependency added increases the complexity and it needs to be evaluated whether the dependency is really required. If in the end only a small function is used from the dependency, it might make more sense to implement this small function instead of adding the dependency.</p> <p>Dependencies should be pinned to the exact version to allow for reproducible builds. Dependencies need to be kept up-to-date, especially minor and patch versions that fix bugs or vulnerabilities. This should be automated (with tools like Renovate or similar).</p> <p>Furthermore, a list of dependencies (Bill of Materials) needs to be maintained. The dependency name, version and license needs to be included. This should be automated if possible.</p>"},{"location":"development/best_practices/best_practices/#methodology","title":"Methodology","text":"<p>Any (app) component should follow the Twelve-Factor App Methodology: https://12factor.net/</p> <ul> <li>Store config in the environment: \u201cAn app\u2019s config is everything that is likely to vary between deploys (staging, production, developer environments, etc).\u201d \\ This allows one to configure different deploys using the environment, e.g., using .env file(s), environment variables, environment files (Docker) etc.</li> </ul>"},{"location":"development/best_practices/best_practices/#reusing-code","title":"Reusing Code","text":"<p>In general, the principle to follow is \u201cDon\u2019t Repeat Yourself (DRY)\u201d.</p> <p>If there is already similar functionality but it does not exactly match what you need to accomplish, consider rewriting the existing functionality to make it more generic.</p> <p>Anything that is reusable should either go into dedicated packages/modules (e.g., utils for smaller functionality) or into their own package. Moving functionality into their own package makes it reusable across projects.</p> <p>For example, across the Opal stack encryption/decryption is used in several components and should ideally be provided by a dedicated package/module that is reused.</p>"},{"location":"development/best_practices/best_practices/#graceful-error-handling-and-helpful-error-messages","title":"Graceful Error Handling and Helpful Error Messages","text":"<p>TODO</p>"},{"location":"development/best_practices/best_practices/#open-source-contribution","title":"Open Source Contribution","text":"<p>TODO</p> <ul> <li>Many of the tools, packages and frameworks are open source (and free)</li> <li>Many are maintained by people in their free time</li> <li>Give back to improve them<ul> <li>Report issues</li> <li>Create fixes if possible</li> </ul> </li> <li>Consider: Sponsorship</li> </ul>"},{"location":"development/best_practices/code_review/","title":"Code Review Guidelines","text":"<p>The goal of these guidelines is to provide an overview of best practices and important things to consider during code review. This applies to both the submitter and reviewer. The resources (and additional ones) this was extracted from are provided at the end.</p>"},{"location":"development/best_practices/code_review/#benefits-of-code-review","title":"Benefits of Code Review","text":"<p>Code Review is important in order to ensure that any changes get reviewed by one more more other developers before being merged into the codebase.</p> <p>In short, the benefits are:</p> <ul> <li>Find bugs &amp; design flaws before the the code is done and especially before customers (patients) find/experience them</li> <li>Shared ownership &amp; knowledge: We are a team and no developer should be the only expert. This also helps prevent the lottery factor, i.e., ensuring there is no single human point of failure.</li> <li>Encourage consistency of code: Increases code quality and makes code easier to maintain long term by yourself and others.</li> </ul>"},{"location":"development/best_practices/code_review/#general","title":"General","text":"<p>Generally, code review should be a friendly discussion. Don't take feedback personally (you are not your code). No one is perfect and it is human to make mistakes. Especially, don't point fingers, it is not a competition. The general goal is to have someone else look at the code which provides a different perspective. It is also an opportunity to learn from each other.</p> <ul> <li>Prioritize code reviews (as a reviewer) and responding to feedback (as the submitter).     Make time in your daily schedule for code review.     Spend max one hour at a time doing code review.     Try to do reviews in 24-48 hours in order for the changes to stay fresh in the author's mind to address feedback.</li> <li>Each change should be reviewed by at least one other developer (ideally 2).</li> <li>Every developer (independent of seniority) should review.     Ideally, the reviewer is someone who wrote the original (or knows the) code that was changed.</li> <li>Automation (such as CI pipelines) should be used as much as possible to prevent reviewers from having to say \"you forgot to...\".     Repositories should also contain a merge request template with a checklist to remind and ensure the submitter took care of everything.</li> <li>Please document the result of discussions in the merge request for future traceability if the discussion happened outside of the merge request.</li> <li>Make use of threads and in-line comments on the merge request.     Mark them as resolved when addressed.</li> <li>Submitting and reviewing are equally important: Be a great submitter and a great reviewer.     See below for more details on how.</li> </ul>"},{"location":"development/best_practices/code_review/#what-to-look-out-for","title":"What to look out for","text":"<p>At a high level, you should look out for the following things in a code review (sources with more details<sup>3</sup> <sup>6</sup>):</p> <ul> <li>Design: Is the code well-designed and appropriate for your system?</li> <li>Functionality: Does the code behave as the author likely intended?     Is the way the code behaves good for its users?</li> <li>Complexity: Could the code be made simpler?     Would another developer be able to easily understand and use this code when they come across it in the future?</li> <li>Tests: Does the code have correct and well-designed automated tests?</li> <li>Naming: Did the developer choose clear names for variables, classes, methods, etc.?</li> <li>Comments: Are the comments clear and useful?</li> <li>Style: Does the code follow our style guides?</li> <li>Documentation: Did the developer also update relevant documentation?</li> </ul> <p>Note: The above list is taken verbatim from Google's Code Review Developer Guide<sup>3</sup>. A more detailed description of each item exists<sup>4</sup>.</p> <p>In addition, for the time being, the reviewer should also checkout the changes and try them out. This is especially helpful for more complex changes or to verify whether what looks like a bug or possible problematic condition/logic in the diff is indeed the case.</p>"},{"location":"development/best_practices/code_review/#how-to-be-a-great-submitter","title":"How to be a great submitter","text":"<p>The following is a short summary of how to be a great submitter (sources with more details<sup>1</sup> <sup>2</sup>):</p> <ul> <li>One concern: Submit one issue per merge request.     If you solve an unrelated problem, create a new merge request.</li> <li>Small MRs: Keep merge requests as small as possible to lower barrier to start review.     It also helps prevent reviewer burnout.     Strive for less than 500 lines.     If the work is too big, try to split it into smaller (logical) pieces.</li> <li>Get feedback early: Make use of Draft merge requests to show your work in progress and get early feedback.     This is especially helpful for architectural and design decisions to show the direction you are going in (before fully doing it) and ensuring that this is the right direction.</li> <li>Primary reviewer: YOU: You are the primary reviewer.     Don't rely on others to catch your mistakes, ensure your code works and is thoroughly tested.     It can be very helpful to look at your changes from a different perspective, i.e., looking at the changes in the merge request yourself and see if you spot anything.     This different look at your code might reveal something you didn't notice before.</li> <li>Context: Provide context in your merge request.     Mention/link the ticket you addressed and document how you addressed it.     Point out any open issues or side-effects.</li> <li>Anticipate feedback: It is a conversation.     Be humble, acknowledge that everyone makes mistakes.     Don't take it personally, you are not your code.</li> <li>Checklist: Try using your own checklist to check for general things to ensure and for things that come up frequently in your reviews.<ul> <li>Ensure readability of code</li> <li>Check for reusable code and utility methods</li> <li>Remove debugger/print statements</li> <li>Is the code maintainable, scalable, secure, resilient?</li> </ul> </li> </ul>"},{"location":"development/best_practices/code_review/#how-to-be-a-great-reviewer","title":"How to be a great reviewer","text":"<p>The following is a short summary of how to be a great submitter (sources with more details<sup>1</sup> <sup>2</sup>):</p> <ul> <li>Clear Feedback: Provide clear and actionable feedback.     Opinions need to be strongly supported.     Share how and why a change is necessary and back it up with supporting documentation, articles etc.     If it is not an important change, prefix your comment with \"nit:\" to let the submitter know that it's just a point of polish.</li> <li>Be Objective: Talk about the code, not the coder (\"This method is missing ...\" instead of \"You forgot to ...\").     It is harder to take it personally and prevents finger-pointing.     Have empathy.</li> <li>Use I-Messages: Formulate your feedback from your point of view by expressing your personal thoughts and impressions.     Use sentences that start with \"I ...\" (I suggest, I think, For me, etc.).</li> <li>Ask Questions: Ask questions instead of giving answers.     It feels less like criticism, can trigger a thought process, and the submitter can explain the rationale.</li> <li>Offer Suggestions: Phrase suggestions accordingly, e.g., \"It might be easier to ...\", \"We tend to do it this way ...\".     Make suggestions clear but accept that there are different solutions.</li> <li>Praise: Don't forget to express your appreciation when you see something good.     Compliment good work &amp; great ideas.</li> <li>Avoid: Avoid the following terms: Simply, Easily, Just, Obviously, Well, actually ...     No one writes bad code on purpose.     This is also an opportunity to learn from each other and grow.</li> <li> <p>Don't be a perfectionist: Don't let perfect get in the way of perfectly acceptable.     \"The goal is better code, not 'exactly the code you would have written'\"<sup>5</sup>.     Google's Guide<sup>3</sup> states:</p> <p>In general, reviewers should favor approving a CL once it is in a state where it definitely improves the overall code health of the system being worked on, even if the CL isn\u2019t perfect.</p> </li> </ul>"},{"location":"development/best_practices/code_review/#o-hig-code-review-guide-lines","title":"O-HIG Code review guide lines","text":""},{"location":"development/best_practices/code_review/#how-to-assign-a-code-review","title":"How to assign a code review","text":"<p>Merge request needs to be approved by at least one <code>maintainer</code> and one <code>developer</code>.</p> <ul> <li>You must use the merge request template established for the given project.</li> <li>Assign one <code>maintainer</code> to review your merge request.</li> <li>Assign one <code>developer</code> to review your merge request.</li> <li>Once both reviews are approved, you can assign a third optional reviewer to double check the merge request or for learning purposes.     This is a good opportunity to have a dev learn about a lesser known part of the project even if the merge request is completed.</li> <li>Try to have a small and shortly reviewable merge request.     Should you anticipate lots of code changes, you can use an assembly branch to trigger multiple smaller code reviews.     The assembly/integration branch can be merged to staging/dev (Explanation of assembly/integration).</li> </ul>"},{"location":"development/best_practices/code_review/#code-review-process","title":"Code review process","text":"<ul> <li>Code review should not wait more than 48 hours to be started, business hours only.     Weekend and holidays are excluded.</li> <li>Every developer should dedicate time each day for code review (1-2 hours).</li> <li>Reviewers should mention in scrum or to whoever is asking them to review if they have too many code reviews</li> <li>Maintainers and owners are responsible to monitor the amount of code review of the project assigned to them.</li> <li>When writing comment(s) use the <code>start a review</code>/<code>add to review</code> options.     This will send an email once the review is ready and not an email for each comment (see GitLab documentation on this feature)</li> <li>Thread can only be resolved by the reviewer who opens it.</li> </ul>"},{"location":"development/best_practices/code_review/#resources","title":"Resources","text":"<p>All referenced sources can be found as footnotes at the bottom of this page. The below list contains extra resources that may be of interest:</p> <ul> <li>Talk: Amazing Code Reviews: Creating a Superhero Collective \u2022 Alejandro Lujan \u2022 GOTO 2019: https://www.youtube.com/watch?v=ly86Wq_E18o</li> <li>How to Make Good Code Reviews Better - Stack Overflow Blog: https://stackoverflow.blog/2019/09/30/how-to-make-good-code-reviews-better/</li> <li>Best Practices for Code Review | SmartBear: https://smartbear.com/learn/code-review/best-practices-for-peer-code-review/</li> </ul> <ol> <li> <p>Presentation and slides on \"Code Review Skills for Pythonistas\": https://www.nnja.io/post/2018/2018-djangocon-code-review/ \u21a9\u21a9</p> </li> <li> <p>Code Review Guidelines for Humans: https://phauer.com/2018/code-review-guidelines/ \u21a9\u21a9</p> </li> <li> <p>Code Review Developer Guidelines - Google: https://google.github.io/eng-practices/review/ \u21a9\u21a9\u21a9</p> </li> <li> <p>What to look for in code review - Google: https://google.github.io/eng-practices/review/reviewer/looking-for.html \u21a9</p> </li> <li> <p>Rebecca's Rules for Constructive Code Reviews - Twitter: https://x.com/i_a_r_n_a/status/623922369376202758 \u21a9</p> </li> <li> <p>Code review guidelines - Code Project: https://www.codeproject.com/Articles/524235/Codeplusreviewplusguidelines \u21a9</p> </li> </ol>"},{"location":"development/best_practices/diagrams/","title":"Diagrams","text":"<p>The recommended way to create and maintain diagrams is within text, i.e., diagrams as code. Diagrams as code is like documentation as code (or more generally everything as code) where diagrams are handled like code. This allows us to track any diagram changes in any version control system.</p> <p>In addition, this provides us the ability to review changes to diagrams before merging them (if necessary). And, it is possible to automate their use or export into different formats.</p> <p>Our main tool for creating diagrams is PlantUML because there exists an extension for the C4 model for architecture diagrams. Another great diagramming tool is Mermaid. It has a great live editor and, as a distinct feature, supports Git commit graphs.</p> <p>Tip</p> <p>GitLab also supports both PlantUML and Mermaid. This means, you can augment your comments or merge request descriptions with diagrams as well to better communicate.</p>"},{"location":"development/best_practices/diagrams/#creating-diagrams","title":"Creating Diagrams","text":"<p>Diagrams can either be created as a standalone file or included directly within a Markdown document. This documentation site is set up with PlantUML Markdown, an extension for Python Markdown.</p> <p>The recommended file extension for standalone files is <code>.puml</code>.</p> <p>To include a diagram directly within Markdown, use the following:</p> <pre><code>```plantuml\n@startuml\nAlice -&gt; Bob: Authentication Request\nBob --&gt; Alice: Authentication Response\n\nAlice -&gt; Bob: Another authentication Request\nAlice &lt;-- Bob: Authentication failed\n@enduml\n```\n</code></pre> <p></p> <p>It is also possible to define a standalone file and include it within a page as follows:</p> <pre><code>```plantuml source=\"docs/diagrams/example.puml\"\n```\n</code></pre> <p></p> <p>The advantage of putting a diagram in its dedicated file is that the diagram is separated and can be automatically processed for other purposes.</p> <p>Important</p> <p>The plugin requires the full path within the repository to be specified. For this reason the recommendation is to place all diagrams within the directory under <code>docs/diagrams/</code>.</p> <p>See the documentation of PlantUML Markdown for all features.</p>"},{"location":"development/best_practices/diagrams/#editors","title":"Editors","text":"<p>While there is the PlantUML online server with a text editor and preview, there is no autocompletion and it is separated from a development workflow using an IDE.</p> <p>Fortunately, there are extensions for IDEs that provide code completion and syntax highlighting in the editor and a preview of the diagram:</p> <ul> <li>Visual Studio Code: PlantUML VSCode extension</li> <li>IntelliJ IDEs: PlantUML Integration</li> </ul>"},{"location":"development/best_practices/diagrams/#plantuml-extensions","title":"PlantUML extensions","text":"<p>PlantUML can be extended to support additional diagrams.</p> <p>A great extension is for the C4 Model. See the C4-PlantUML GitHub repository.</p>"},{"location":"development/best_practices/diagrams/#notation-tips","title":"Notation Tips","text":"<p>The following notation tips are extracted from the talk \"Visualising software architecture with the C4 model\" by Simon Brown (YouTube):</p> <ul> <li>Titles: Short and meaningful, include the diagram type, numbered if diagram order is important.   Example: System Context diagram for Financial Risk System</li> <li>Layout</li> <li>Visual consistency: Try to be consistent with notation and element positioning across diagrams (same colour codings and shapes)</li> <li>Acronyms: Be wary of using acronyms, especially those related to the business/domain that you work in (focus more on domain-specific/business-specific acronyms)</li> <li>Elements: Start with simple boxes containing the element name, type, technology (if appropriate) and a description/responsibilities</li> <li>Lines: Favour uni-directional lines showing the most important dependencies or data flow, with an annotation to be explicit about the purpose of the line and direction<ul> <li>Summarize the intent of the relationship (SPA \"makes API calls using\" API application)</li> <li>Summarize, yet be specific (\"Makes API calls using\" vs. \"Uses\")</li> <li>Show both directions when the intents are different</li> <li>Beware of hiding the true story: \"Sends customer update messages to [via Kafka topic X]\"</li> <li>Add more words to make the intent explicit (\"Sends trade data to\" vs. \"trade data\")</li> </ul> </li> <li>Key/Legend: Explain shapes, line styles, colours, borders, acronyms etc. (even if your notation seems obvious)</li> <li>Use shape, colour and size to complement a diagram that already makes sense</li> <li>Use icons to supplement text, not replace it (additional layer of information)</li> <li>Increase the readability of software architecture diagrams, so they can stand alone</li> <li>Tell stories: Any narrative (on top of the diagram) should complement the diagram rather than explain it</li> </ul> <p>A checklist also Notation Checklist: https://c4model.com/diagrams/checklist</p>"},{"location":"development/guides/docker/","title":"Docker","text":""},{"location":"development/guides/docker/#best-practices","title":"Best practices","text":"<ul> <li>Specify full version tag to allow for reproducible builds (e.g., <code>node:17.3.0-bullseye</code> instead of <code>node:17</code>, <code>node:17-bullseye</code> etc.)</li> <li>Don\u2019t run app as root in container</li> </ul>"},{"location":"development/guides/docker/#resources","title":"Resources","text":"<ul> <li>Best practices for writing Dockerfiles | Docker Documentation (see also Reviewing the official Dockerfile best practices: good, bad, insecure)</li> <li>Broken by default: why you should avoid most Dockerfile examples</li> <li>The worst so-called \u201cbest practice\u201d for Docker</li> <li>Less capabilities, more security: preventing Docker escalation attacks</li> </ul>"},{"location":"development/guides/javascript/","title":"JavaScript","text":""},{"location":"development/guides/javascript/#code-style","title":"Code Style","text":"<ul> <li>Airbnb JavaScript Style Guide</li> <li>Enforced by eslint<ul> <li>eslint-config-airbnb-base</li> </ul> </li> </ul>"},{"location":"development/guides/python/","title":"Python","text":""},{"location":"development/guides/python/#code-style","title":"Code Style","text":"<ul> <li>PEP 8 \u2014 the Style Guide for Python Code</li> <li>PEP 257 -- Docstring Conventions | Python.org</li> <li>Enforced by flake8</li> <li>Consistent use of quotes: Single quotes (enforced by flake8-quotes)</li> <li>Sort Imports (enforced by isort via flake8-isort)</li> <li>Write type hints to help with static type checking through mypy<ul> <li>Type Hints in Python \u2014 Everything You Need To Know In 5 Minutes</li> <li>Type hints cheat sheet (Python 3) \u2014 Mypy documentation</li> <li>Support for type hints \u2014 Python 3 documentation</li> </ul> </li> </ul>"},{"location":"development/guides/python/#type-checking","title":"Type Checking","text":"<ul> <li>Static type checking is performed using mypy</li> <li>To fully leverage this, type hints should be added to all code (this is enforced by mypy)</li> <li>This also helps the IDE in providing appropriate help when writing code</li> <li>A lot of Python packages support type hints and provide mypy types declarations (e.g., there is a <code>types-requests</code> package for <code>requests</code>, mypy will warn about this when run)</li> </ul>"},{"location":"development/guides/python/#unit-testing","title":"Unit Testing","text":"<p>Unit tests are executed using pytest and coverage is checked using coverage.</p> <p>Additionally, mocking can be done using the additional pytest plugin pytest-mock.</p> <p>For complex migrations in Django that require Python code to run, there is the plugin django-test-migrations which allows to accomplish this.</p>"},{"location":"development/guides/python/#upgrading-dependencies","title":"(Upgrading) Dependencies","text":"<p>If not already done by an automatic dependency checker (see above), dependencies can be upgraded via pip-upgrader.</p>"},{"location":"development/guides/python/#django-migrations","title":"Django Migrations","text":"<p>When writing migrations in Django that require custom Python code to be executed (using the RunPython migration), forward and backward code needs to be provided to ensure that the database can be migrated in both directions without encountering any errors.</p> <p>TBD</p> <p>Have a checker check for this (pylint has a plugin)</p>"},{"location":"development/guides/self_signed_certificates/","title":"Generating Self-Signed Certificates","text":"<p>These instructions pertain to the generation of self-signed certificates used to encrypt interactions between a server and a client application/container (such as Alembic, DBV, the listener, etc) via SSL/TLS.</p> <p>You can either run a container with <code>openssl</code> to generate certificates, or use a program like git bash for windows users.</p> <p>These instructions are based on the official MySQL Documentation on Creating SSL Certificates.</p> <p>Run a container with <code>alpine</code> that has access to a directory for the certs on the host:</p> <pre><code>docker run --rm -it -v $PWD/certs:/certs alpine:latest sh\n</code></pre> <p>Install <code>openssl</code>:</p> <pre><code>apk add openssl\n</code></pre> <p>Note: Execute the following commands inside the <code>/certs</code> directory or move the required files there at the end to make them available on your host.</p> <p>Generate the certificate authority (CA) certificates:</p> <pre><code># Create CA private key\nopenssl genrsa 4096 &gt; ca-key.pem\n# Create CA public key\n#\n# Country Name: CA\n# State: QC\n# Locality: Montreal\n# Organization Name: Opal Med Apps CA\n# Common Name: ca.opalmedapps.dev\n# Email Address: &lt;your email&gt;\n# the rest can be left empty\nopenssl req -new -x509 -nodes -days 3600 -key ca-key.pem -out ca.pem\n</code></pre> <p>Generate the server certificate:</p> <pre><code># Create the server's private key and a certificate request for the CA\n#\n# Country Name: CA\n# State: QC\n# Locality: Montreal\n# Organization Name: Opal Med Apps\n# Common Name: db\n# Email Address: &lt;your email&gt;\n# the rest can be left empty (the challenge password has to be empty)\nopenssl req -newkey rsa:4096 -days 3600 -nodes -keyout server-key.pem -out server-req.pem\n# let the CA issue a certificate for the server\nopenssl x509 -req -in server-req.pem -days 3600 -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem\n</code></pre> <p>These server certificates are meant to be used by your database for authenticating incoming requests while the <code>ca.pem</code> file is used by clients to make requests to the database.</p> <p>Verify that the server certificate is valid:</p> <pre><code>openssl verify -CAfile ca.pem server-cert.pem\n</code></pre> <p>We can also output a plain-text version of the server certificate with details of its generation:</p> <pre><code>openssl x509 -in server-cert.pem -text -noout\n</code></pre>"},{"location":"development/guides/sequence_diagrams/","title":"Sequence Diagrams","text":"<p>Sequence diagrams are part of the Unified Modeling Language (UML), a standardized general-purpose graphical modeling language.</p> <p>Sequence diagrams are one kind of interaction diagram which focus on the message interchange between different actors and software systems. They show the sequence of messages that are exchanged.</p> <p>Sequence diagrams can be used to convey message exchanges at different levels of abstraction and to different stakeholders.</p>"},{"location":"development/guides/sequence_diagrams/#important-elements-of-sequence-diagrams","title":"Important Elements of Sequence Diagrams","text":"A sample sequence diagram with some import elements (Source) <p>A detailed overview of all the elements can be found on uml-diagrams.org.</p>"},{"location":"development/guides/sequence_diagrams/#example","title":"Example","text":"<p>Below are two examples, one showing a high-level diagram and the second one showing a more detailed diagram that is closer to code. Basically, sequence diagrams can be used to show interactions at different abstraction levels.</p>"},{"location":"development/guides/sequence_diagrams/#high-level","title":"High-level","text":"<p>Taken from the official PlantUML Sequence Diagrams documentation.</p>"},{"location":"development/guides/sequence_diagrams/#low-level","title":"Low-level","text":""},{"location":"user/","title":"User Guide","text":"<p>TBD</p>"}]}